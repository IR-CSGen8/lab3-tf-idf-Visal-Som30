{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720e4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math #important library , calculate log\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd950e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample collection of documents\n",
    "documents = [\n",
    "    \"Scientists have discovered a new species of marine life in the deep ocean.\",\n",
    "    \"NASA's Mars rover is searching for signs of ancient life on the Red Planet.\",\n",
    "    \"The stock market experienced a significant drop in trading today.\",\n",
    "    \"Astronomers have identified a distant galaxy with unusual star formations.\",\n",
    "    \"The government announced new measures to combat climate change.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ea50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for lemmatization (a simple example, not comprehensive)\n",
    "lemmatization_dict = {\n",
    "    \"species\": \"specie\",\n",
    "    \"species\": \"species\",\n",
    "    \"oceans\": \"ocean\",\n",
    "    \"ocean's\": \"ocean\",\n",
    "    \"rover\": \"rover\",\n",
    "    \"discovered\":\"discover\",\n",
    "    \"experienced\":\"experience\",\n",
    "    \"rovers\": \"rover\",\n",
    "    \"trading\": \"trade\",\n",
    "    \"identified\": \"identify\",\n",
    "    \"identifies\": \"identify\",\n",
    "    \"formations\": \"formation\",\n",
    "    \"governments\": \"government\",\n",
    "    \"measures\": \"measure\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f1f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terms = [lemmatization_dict.get(term, term) for term in terms]\n",
    "# terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed247b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize documents into words (terms), remove punctuation, and lemmatize\n",
    "def preprocess_text(document):\n",
    "    terms = document.lower().split()\n",
    "    terms = [term.strip(string.punctuation) for term in terms]\n",
    "    terms = [lemmatization_dict.get(term, term) for term in terms]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cee75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a set of unique terms (vocabulary)\n",
    "vocabulary = set()\n",
    "# you code here ...\n",
    "\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da0c442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the term frequency (TF) for each term in each document\n",
    "tf_values = {term: [0] * len(documents) for term in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc32da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 2 (1722801126.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    tf_values\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate Term Frequency (TF)\n",
    "for i, document in enumerate(documents):\n",
    "    # your code here ....\n",
    "\n",
    "tf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d91fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Inverse Document Frequency (IDF)\n",
    "idf_values = {}\n",
    "total_documents = len(documents)\n",
    "for term in vocabulary:\n",
    "    # your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be824663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF values\n",
    "tfidf_values = []\n",
    "for i, document in enumerate(documents):\n",
    "    terms = preprocess_text(document)\n",
    "    tfidf_document = []\n",
    "    for term in vocabulary:\n",
    "        tf = tf_values[term][i]\n",
    "        idf = idf_values[term]\n",
    "        tfidf = tf * idf\n",
    "        tfidf_document.append(tfidf)\n",
    "    tfidf_values.append(tfidf_document)\n",
    "tfidf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f53d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TF-IDF values to a DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_values, columns=list(vocabulary))\n",
    "\n",
    "# Display TF-IDF results\n",
    "print(\"TF-IDF:\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcbe8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF-IDF results to a CSV file (optional)\n",
    "# df_tfidf.to_csv(\"tfidf_custom_preprocessed_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36077c4e",
   "metadata": {},
   "source": [
    "# Using Libraries for Lemmatization and Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your machine doesn't have these libraries, you need to install them\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download the punkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69087c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize NLTK's lemmatizer and download stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "# Initialize NLTK's lemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Tokenize documents into words (terms), remove punctuation, lemmatize, and remove stopwords\n",
    "def preprocess_text(document):\n",
    "    terms = nltk.word_tokenize(document)\n",
    "    terms = [term.strip(string.punctuation) for term in terms]\n",
    "    terms = [ps.stem(term) for term in terms]\n",
    "    terms = [term.lower() for term in terms if term not in stopwords.words('english')]\n",
    "    return ' '.join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c050db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text in the documents\n",
    "preprocessed_documents = # your code here ...\n",
    "\n",
    "# Create a TfidfVectorizer instance\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the preprocessed documents to compute TF-IDF values CADT@0zJanZ!\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display TF-IDF results\n",
    "print(\"TF-IDF:\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40a2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
